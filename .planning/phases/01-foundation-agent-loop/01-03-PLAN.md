---
phase: 01-foundation-agent-loop
plan: 03
type: execute
wave: 2
depends_on: ["01-01", "01-02"]
files_modified:
  - src/agent/client.py
  - src/agent/prompts.py
  - src/agent/loop.py
  - src/agent/__init__.py
  - src/main.py
autonomous: false
user_setup:
  - service: deepseek
    why: "LLM API for agent reasoning and tool calling"
    env_vars:
      - name: DEEPSEEK_API_KEY
        source: "DeepSeek Platform -> API Keys (https://platform.deepseek.com/api_keys)"

must_haves:
  truths:
    - "Agent executes think-act-observe loop calling FastMCP tools via DeepSeek API"
    - "Agent ends by calling task_completed or hitting 50-step timeout"
    - "Full trajectory is captured with thought, action, observation per step plus final outcome"
    - "Trajectory includes step count, success/failure, wall-clock duration, and failure reason"
    - "Running main.py on a single task produces a .jsonl file with the complete trajectory"
  artifacts:
    - path: "src/agent/client.py"
      provides: "AsyncOpenAI wrapper for DeepSeek with retry logic"
      exports: ["DeepSeekClient"]
    - path: "src/agent/prompts.py"
      provides: "System prompt for autonomous agent execution"
      exports: ["AUTONOMOUS_AGENT_PROMPT"]
    - path: "src/agent/loop.py"
      provides: "Think-act-observe execution loop with trajectory capture"
      exports: ["run_task"]
    - path: "src/main.py"
      provides: "CLI entry point to run agent on single ALFWorld task"
  key_links:
    - from: "src/agent/loop.py"
      to: "src/agent/client.py"
      via: "DeepSeekClient.chat() for LLM calls with tools"
      pattern: "client\\.chat"
    - from: "src/agent/loop.py"
      to: "src/environment/env_manager.py"
      via: "env_manager.step() to execute tool actions"
      pattern: "env_manager\\.step"
    - from: "src/agent/loop.py"
      to: "src/trajectory/models.py"
      via: "Step/Trajectory dataclass construction"
      pattern: "Step\\(|Trajectory\\("
    - from: "src/main.py"
      to: "src/trajectory/storage.py"
      via: "append_trajectory to persist completed run"
      pattern: "append_trajectory"
    - from: "src/agent/loop.py"
      to: "src/environment/server.py"
      via: "reads tool definitions from mcp to pass to DeepSeek"
      pattern: "mcp.*tool"
---

<objective>
Implement the autonomous agent loop that connects DeepSeek API to ALFWorld environment, executing think-act-observe cycles and capturing complete trajectories.

Purpose: This is the core of Phase 1 -- the agent that runs ALFWorld tasks autonomously. It wires together the environment (Plan 02), trajectory logging (Plan 01), and the DeepSeek LLM API into a working end-to-end system.
Output: Working agent that can run a single ALFWorld task, make tool calls, capture the full trajectory, and persist it to disk.
</objective>

<execution_context>
@/Users/anas/.claude/get-shit-done/workflows/execute-plan.md
@/Users/anas/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation-agent-loop/01-RESEARCH.md
@.planning/phases/01-foundation-agent-loop/01-01-SUMMARY.md
@.planning/phases/01-foundation-agent-loop/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement DeepSeek client, agent prompt, and think-act-observe loop</name>
  <files>
    src/agent/client.py
    src/agent/prompts.py
    src/agent/loop.py
    src/agent/__init__.py
  </files>
  <action>
    **src/agent/client.py** -- DeepSeek API wrapper:

    Class `DeepSeekClient`:
    - `__init__(self, api_key: str | None = None, model: str = "deepseek-chat")`:
      - Create AsyncOpenAI(base_url="https://api.deepseek.com", api_key=api_key or os.environ["DEEPSEEK_API_KEY"])
      - Store model name
    - `async chat(self, messages: list[dict], tools: list[dict] | None = None, temperature: float = 0.7) -> ChatCompletion`:
      - Call self.client.chat.completions.create() with model, messages, tools, temperature
      - Wrap with tenacity retry: wait_exponential(multiplier=1, min=4, max=60), stop_after_attempt(5), retry on openai API errors (RateLimitError, APIConnectionError, InternalServerError)
      - Add asyncio.wait_for with 120-second timeout per call (prevents stuck on DeepSeek's 10-min connection limit)

    IMPORTANT: Use model="deepseek-chat" for function calling, NOT "deepseek-reasoner" (reasoner doesn't support tool calls -- research pitfall #1).

    **src/agent/prompts.py** -- System prompt:

    Define `AUTONOMOUS_AGENT_PROMPT` as a string constant. Content:
    - Tell the agent it is autonomous, running WITHOUT human supervision
    - List all available tools with brief descriptions matching the FastMCP tool names exactly: go_to, take, put, open_receptacle, close_receptacle, clean, heat, cool, use, examine, inventory, task_completed
    - Instructions: read task carefully, think step-by-step before acting, use tools to explore and manipulate, call task_completed(success=True/False, summary="...") when done or stuck, max 50 steps
    - Emphasize: describe reasoning before each action, be systematic (explore first, then act), if stuck try a different approach

    **src/agent/loop.py** -- Core agent execution:

    Async function `run_task(task_description: str, task_id: str, task_type: str, env_manager, tools_spec: list[dict], client: DeepSeekClient, max_steps: int = 50, wall_clock_timeout: float = 300.0) -> Trajectory`:

    Implementation:
    1. Record start_time
    2. Initialize messages = [system prompt, user message with task_description]
    3. Initialize steps list
    4. Loop for max_steps iterations (wrapped in asyncio.wait_for for wall_clock_timeout):
       a. Call client.chat(messages, tools=tools_spec)
       b. Extract response message
       c. If message has tool_calls:
          - For EACH tool call in message.tool_calls:
            - Parse function name and arguments
            - If name == "task_completed": parse success/summary from args, set completion flag, create Step, break
            - Otherwise: call env_manager.step() with the appropriate ALFWorld command string
            - IMPORTANT: Map tool names to ALFWorld commands correctly:
              go_to(location) -> "go to {location}"
              take(object_name) -> "take {object_name}"
              put(object_name, receptacle) -> "put {object_name} in/on {receptacle}"
              open_receptacle(receptacle) -> "open {receptacle}"
              close_receptacle(receptacle) -> "close {receptacle}"
              clean(object_name, receptacle) -> "clean {object_name} with {receptacle}"
              heat(object_name, receptacle) -> "heat {object_name} with {receptacle}"
              cool(object_name, receptacle) -> "cool {object_name} with {receptacle}"
              use(object_name) -> "use {object_name}"
              examine(object_name) -> "examine {object_name}"
              inventory() -> "inventory"
            - Create Step(step=i, thought=message.content, action=name, action_input=arguments_json, observation=result)
            - Append step to steps list
            - Add assistant message + tool result message to messages (following OpenAI format: assistant message with tool_calls, then tool role message with tool_call_id and content)
          - If task_completed was called, break outer loop
       d. If no tool_calls: agent failed to act. Log a step with action="no_action", break loop.
    5. Calculate duration
    6. Determine success: True if task_completed(success=True) was called, False otherwise
    7. Determine failure_reason: "timeout" if max_steps hit, "wall_clock_timeout" if time exceeded, "no_tool_call" if agent stopped calling tools, "agent_declared_failure" if task_completed(success=False), None if success
    8. Get env_done from env_manager.done
    9. Construct and return Trajectory

    IMPORTANT: The tool name to ALFWorld command mapping must be in loop.py (or a helper), NOT in the FastMCP tools themselves. The FastMCP tools exist for the MCP protocol; the agent loop calls env_manager.step() directly. The agent loop receives tool call requests from DeepSeek, maps them to ALFWorld commands, and executes via env_manager.

    Wait -- CLARIFICATION on architecture: There are two valid approaches:

    Approach A (Direct): Agent loop gets tool calls from DeepSeek -> maps to ALFWorld commands -> calls env_manager.step() directly. FastMCP tools exist but aren't called during agent execution. Tools spec is manually constructed to match what the env supports.

    Approach B (Via MCP): Agent loop gets tool calls from DeepSeek -> calls FastMCP tools via MCP client. FastMCP tools call env_manager.step() internally.

    USE APPROACH A (Direct). It's simpler for single-agent execution, avoids MCP client/server overhead, and gives direct control over the loop. The FastMCP server is still defined (Plan 02 created it) and will be used in Phase 2 for parallel execution, but for now the agent loop calls env_manager directly.

    Build the tools_spec (list of OpenAI function-calling tool definitions) as a helper function `build_tools_spec() -> list[dict]` in loop.py. This generates the JSON schema for each of the 11 tools matching the FastMCP tool signatures.

    Update src/agent/__init__.py to export DeepSeekClient, run_task, AUTONOMOUS_AGENT_PROMPT.
  </action>
  <verify>
    Run:
    ```
    python -c "
    from src.agent.client import DeepSeekClient
    from src.agent.prompts import AUTONOMOUS_AGENT_PROMPT
    from src.agent.loop import run_task, build_tools_spec
    tools = build_tools_spec()
    print(f'Tools spec count: {len(tools)}')
    assert len(tools) >= 11, f'Expected 11+ tools, got {len(tools)}'
    print(f'Tool names: {[t[\"function\"][\"name\"] for t in tools]}')
    print(f'Prompt length: {len(AUTONOMOUS_AGENT_PROMPT)} chars')
    assert 'task_completed' in AUTONOMOUS_AGENT_PROMPT
    assert 'autonomous' in AUTONOMOUS_AGENT_PROMPT.lower()
    print('agent components OK')
    "
    ```
  </verify>
  <done>DeepSeekClient wraps AsyncOpenAI with retry logic. AUTONOMOUS_AGENT_PROMPT instructs autonomous execution with all 11 tools. run_task implements think-act-observe loop with step/wall-clock timeouts, tool-to-command mapping, and Trajectory construction. build_tools_spec generates OpenAI function-calling schema for all 11 tools.</done>
</task>

<task type="auto">
  <name>Task 2: Create main.py entry point and run end-to-end test</name>
  <files>
    src/main.py
  </files>
  <action>
    Create src/main.py as the CLI entry point:

    - Parse CLI arguments: --task-index (int, default 0, which ALFWorld task to run), --max-steps (int, default 50), --output-dir (str, default "data/trajectories")
    - Use argparse for argument parsing
    - Async main function:
      1. Load environment: EnvManager().load()
      2. Reset to task (if task-index provided, reset multiple times to reach that task -- ALFWorld cycles through tasks sequentially on reset)
      3. Get task observation, task_id, task_type
      4. Create DeepSeekClient()
      5. Build tools_spec
      6. Call run_task(task_description=observation, task_id=task_id, task_type=task_type, env_manager=env_manager, tools_spec=tools_spec, client=client, max_steps=args.max_steps)
      7. Print summary: task_id, success, steps taken, duration
      8. Save trajectory via append_trajectory to output_dir/trajectories.jsonl
      9. If env_manager.done != trajectory.success, print WARNING about discrepancy

    - Use asyncio.run(main()) as entry point
    - Handle KeyboardInterrupt gracefully (print partial results)
    - Handle missing DEEPSEEK_API_KEY with clear error message

    Run actual end-to-end test: `python src/main.py --task-index 0 --max-steps 10`
    (Use --max-steps 10 to keep it short for testing. This will run the agent on the first ALFWorld task for up to 10 steps.)

    The test should:
    - Load ALFWorld environment
    - Reset to task 0
    - Run agent loop with DeepSeek API calls
    - Capture trajectory
    - Save to data/trajectories/trajectories.jsonl
    - Print summary

    If the test fails due to DEEPSEEK_API_KEY not set, that's expected -- the checkpoint below handles that.
  </action>
  <verify>
    Run: `DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY:-test} python -c "from src.main import *; print('main imports OK')"`

    Then run actual end-to-end (requires API key):
    `python src/main.py --task-index 0 --max-steps 10`

    Expected output:
    - Task description printed
    - Agent takes 1-10 steps
    - Summary printed (task_id, success/failure, steps, duration)
    - File data/trajectories/trajectories.jsonl created with 1 trajectory

    Verify trajectory file:
    `python -c "from src.trajectory.storage import load_trajectories; from pathlib import Path; ts = load_trajectories(Path('data/trajectories/trajectories.jsonl')); print(f'Trajectories: {len(ts)}'); t = ts[0]; print(f'Steps: {t.total_steps}, Success: {t.success}, Duration: {t.duration_seconds:.1f}s')"`
  </verify>
  <done>main.py runs agent on single ALFWorld task via CLI. Agent makes real DeepSeek API calls, executes tools, captures trajectory with all fields populated, persists to JSONL file. End-to-end pipeline works.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete Phase 1 agent pipeline: ALFWorld environment + DeepSeek agent loop + trajectory logging. The agent runs autonomously on a single ALFWorld task, making real API calls, executing environment actions, and saving the full trajectory to disk.</what-built>
  <how-to-verify>
    1. Ensure DEEPSEEK_API_KEY is set in your environment
    2. Run: `python src/main.py --task-index 0 --max-steps 15`
    3. Observe:
       - Agent receives a task description (e.g., "put a clean sponge on the counter")
       - Agent makes tool calls (go_to, examine, take, etc.)
       - Each step shows thought + action + observation
       - Agent either calls task_completed or hits step limit
       - Summary shows task_id, success/failure, step count, duration
    4. Check trajectory file: `cat data/trajectories/trajectories.jsonl | python -m json.tool` (should show structured trajectory with all steps)
    5. Verify observations are natural language only (no JSON state, no scores)
  </how-to-verify>
  <resume-signal>Type "approved" if agent runs tasks and trajectories are captured correctly, or describe any issues.</resume-signal>
</task>

</tasks>

<verification>
1. `python src/main.py --task-index 0 --max-steps 10` completes without crash
2. Agent makes real DeepSeek API calls and receives tool call responses
3. Tool calls map correctly to ALFWorld commands
4. Trajectory JSONL file contains all fields: task_id, task_description, task_type, success, steps (with thought/action/observation), total_steps, duration_seconds, failure_reason, env_done
5. Observations are natural language strings only
6. Agent stops on task_completed call or step limit
</verification>

<success_criteria>
- DeepSeekClient connects to api.deepseek.com with retry logic and per-call timeout
- Agent prompt instructs autonomous execution with all 11 tools listed
- run_task executes think-act-observe loop for up to max_steps or wall_clock_timeout
- Tool calls correctly map to ALFWorld commands via env_manager.step()
- Trajectory captures every step's thought, action, action_input, observation
- Trajectory includes task_id, task_type, success, total_steps, duration_seconds, failure_reason, env_done
- main.py runs single task from CLI and saves trajectory to JSONL
- End-to-end test produces valid trajectory file with real data
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-agent-loop/01-03-SUMMARY.md`
</output>
